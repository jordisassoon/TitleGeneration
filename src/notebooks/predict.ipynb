{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/infres/amathur-23/kaggle_nlp/challenge_files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/amathur-23/kaggle_nlp/challenge_files/nlp2/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd ~/kaggle_nlp/challenge_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "device = \"cuda:1\"\n",
    "\n",
    "# Load the Camembert model\n",
    "model_path = 'barthez_finetuned_early'\n",
    "out_path = f\"predictions_{model_path}_2.csv\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d8cf0103de4dbe8699e039a724a61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the test data\n",
    "data_path = 'data/test_text.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Generate summaries for the 'text' column\n",
    "summaries = []\n",
    "ids = []\n",
    "for i, text in tqdm(df['text'].items()):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors='pt', max_length=512, truncation=True).to(device)\n",
    "    summary_ids = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    ids.append(i)\n",
    "    summaries.append(summary)\n",
    "\n",
    "\n",
    "# Create a new dataframe with the 'text' and generated headlines\n",
    "df_predictions = pd.DataFrame({'ID': ids, 'titles': summaries})\n",
    "\n",
    "# Save the dataframe to a new CSV file\n",
    "df_predictions.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>L'accès à leurs origines une fois la majorité ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>En 2017, François Bayrou s'était associé à Emm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ils ne passeront pas Noël ensemble. Le quotidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dans un message publié pour Noël, le fondateur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Le suspense a duré jusqu'au bout. Le mardi 4 s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               text\n",
       "0   0  L'accès à leurs origines une fois la majorité ...\n",
       "1   1  En 2017, François Bayrou s'était associé à Emm...\n",
       "2   2  Ils ne passeront pas Noël ensemble. Le quotidi...\n",
       "3   3  Dans un message publié pour Noël, le fondateur...\n",
       "4   4  Le suspense a duré jusqu'au bout. Le mardi 4 s..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Le texte prévoit que les enfants nés d'un don ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Le président du MoDem estime qu'il y a là un m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>La Dépêche révèle mercredi 18 décembre les des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>L'ostéopathe Nicolas Lemonnier a décidé de se ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Comme le révèle le Journal du Dimanche, un tén...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             titles\n",
       "0   0  Le texte prévoit que les enfants nés d'un don ...\n",
       "1   1  Le président du MoDem estime qu'il y a là un m...\n",
       "2   2  La Dépêche révèle mercredi 18 décembre les des...\n",
       "3   3  L'ostéopathe Nicolas Lemonnier a décidé de se ...\n",
       "4   4  Comme le révèle le Journal du Dimanche, un tén..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# from transformers import FlaubertModel, BertModel, AutoTokenizer\n",
    "\n",
    "# class Seq2SeqModel(nn.Module):\n",
    "#     def __init__(self, encoder, decoder):\n",
    "#         super(Seq2SeqModel, self).__init__()\n",
    "#         self.encoder = encoder\n",
    "#         self.decoder = decoder\n",
    "\n",
    "#     def forward(self, input_ids, decoder_input_ids):\n",
    "#         encoder_outputs = self.encoder(input_ids)[0]\n",
    "#         decoder_outputs = self.decoder(decoder_input_ids, encoder_hidden_states=encoder_outputs)\n",
    "#         return decoder_outputs\n",
    "\n",
    "# # Load FlauBERT as the encoder\n",
    "# encoder = FlaubertModel.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
    "\n",
    "# # Load BERT as the decoder\n",
    "# decoder = FlaubertModel.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
    "\n",
    "# # Create the seq2seq model\n",
    "# model = Seq2SeqModel(encoder, decoder)\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_token_id = tokenizer.cls_token_id\n",
    "\n",
    "# print(cls_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_text = \"Pouvez-vous creer une sommaire pour ce texte?\"\n",
    "\n",
    "# # Tokenize input text\n",
    "# input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")  # Use \"pt\" for PyTorch tensors\n",
    "# decoder_input_ids = torch.tensor([[1w]])\n",
    "\n",
    "# # Generate output sequence\n",
    "# output_ids = model(input_ids, decoder_input_ids)\n",
    "\n",
    "# # Decode output tokens to text\n",
    "# output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
